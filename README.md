# R2DE_Intro_Hadoop

Hadoop is a framework designed for handling and processing large-scale data (Big Data) in a distributed environment. It is well-known for its ability to manage massive datasets efficiently and its scalability to accommodate growing data needs.

## Architecture
The architecture is divided into two main layers: the Batch Layer and the Speed Layer.

![Hadoop](https://github.com/user-attachments/assets/7860dc3b-922f-4ec4-848f-88976f336dc1)


### 1. Batch Layer
The Batch Layer handles large volumes of data processed in periodic intervals. It is ideal for running complex queries on large datasets that do not require real-time results.

- **Source System:** Data originates as text files generated by various source systems.
- **Data Ingestion:** Data is ingested into the Hadoop ecosystem using a Command Line Interface (CLI).
- **Storage:** The ingested data is stored in the Hadoop Distributed File System (HDFS) as text files.
- **Processing:** Apache SparkSQL is utilized to perform batch processing on the stored data.
- **Data Query:** Hive is used for querying the processed data and managing data warehousing tasks.
- **Workflow Management:** Apache Oozie orchestrates and manages the workflows, ensuring that tasks are executed in the correct sequence and on schedule.

### 2. Speed Layer
The Speed Layer focuses on real-time data processing, ensuring that data is processed and made available with minimal delay.

- **Source System:** Log files are generated by source systems and serve as the input for real-time processing.
- **Data Ingestion:** Apache Flume is responsible for collecting and aggregating log data before forwarding it to HDFS.
- **Storage:** The real-time log data is also stored in HDFS as text files.
- **Processing:** Spark Streaming processes the incoming data streams in real-time, allowing for near-instantaneous insights.
- **Real-Time Storage:** The processed real-time data is stored in HBase, providing fast access for downstream systems that require immediate data.
- **Data Query:** As with the Batch Layer, Hive is used to query and manage the processed data.

## Components Used
- **Apache Hadoop:** A framework that allows for the distributed processing of large datasets across clusters of computers.
- **Apache HDFS:** The Hadoop Distributed File System for storing large datasets.
- **Apache SparkSQL:** A component of Apache Spark used for processing structured data.
- **Apache Spark Streaming:** A Spark component that enables scalable, high-throughput, and fault-tolerant stream processing of live data streams.
- **Apache Hive:** A data warehouse software that facilitates reading, writing, and managing large datasets residing in distributed storage.
- **Apache HBase:** A non-relational, distributed database modeled after Google's Bigtable and is written in Java.
- **Apache Flume:** A service designed for efficiently collecting, aggregating, and moving large amounts of log data.
- **Apache Oozie:** A workflow scheduler system to manage Hadoop jobs.
